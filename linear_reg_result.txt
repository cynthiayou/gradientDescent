Using gradient descent, the trained theta is: 
[22.22877533 -1.10136593  0.48593783 -0.6215547   0.2402716  -0.66838739
  3.19468174 -0.52322073 -2.05784733  1.07459863 -0.62827248 -2.00596568
  1.10428658 -3.07604221]
RSME for training set:3.136964133804761
RSME for test set: 2.6416746731051073


Using stachostic gradient descent (SGD), the trained theta is: 
[22.28592273 -0.93008161  0.08037915 -0.59097983  0.68599225 -0.42421131
  3.18780224 -0.39309587 -1.66144482  1.08558289 -0.62529199 -2.05343171
  0.9091152  -3.48273036]
RSME for training set:3.179347035699988
RSME for test set: 2.5758650274921164


Using SGD with momentum, the trained theta is: 
[22.14010491 -0.71297965  1.16506676 -0.52983723 -0.11170662 -1.85987415
  1.62390347  1.40400134 -1.28257125  2.6981608  -1.69326242 -2.03362995
  0.65659079 -4.45650825]
RSME for training set:3.3002639690406563
RSME for test set: 2.691200841684111


Using SGD with Nesterov momentum, the trained theta is: 
[22.11389757 -0.81106904  1.01207194  0.39187606  1.52263969 -1.69174223
  2.94705644  0.60569895 -1.37032578  1.94791469 -1.55837533 -2.10550082
  0.91027652 -3.88940842]
RSME for training set:3.290658158764896
RSME for test set: 2.523507301882662


Using AdaGrad, the trained theta is: 
[20.9635316  -1.23448547 -0.09005581 -0.63136323  0.15354539 -0.682199
  3.44336451 -0.4491351  -1.52535883  0.42035833 -0.24008087 -1.88753053
  0.88612503 -3.13771569]
RSME for training set:3.3587039494925337
RSME for test set: 2.851314016276599


